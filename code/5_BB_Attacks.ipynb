{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/lib/python3.11/site-packages/art/estimators/certification/__init__.py:29: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from art.attacks.evasion import HopSkipJump, ZooAttack, BoundaryAttack\n",
    "from art.attacks.evasion.fast_gradient import FastGradientMethod\n",
    "from art.estimators.classification.query_efficient_bb import QueryEfficientGradientEstimationClassifier\n",
    "from art.estimators.classification import KerasClassifier\n",
    "\n",
    "from adversarialdefence.utils import ModelUtils, GeneralUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Data Loading***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1715326, 49)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../csv/CICIDS2017_improved-preprocessed.csv')\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of benign samples: 1432918\n",
      "Number of anomalous samples: 282408\n"
     ]
    }
   ],
   "source": [
    "df_benign = df[df['Label'] == 0]\n",
    "df_anomalous = df[df['Label'] == 1]\n",
    "\n",
    "print(f'Number of benign samples: {df_benign.shape[0]}')\n",
    "print(f'Number of anomalous samples: {df_anomalous.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Load models and scalers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Nadam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "autoencoder = load_model('../modelli/autoencoder_best_weights_96-96.hdf5')\n",
    "dnn = load_model('../modelli/DNN_best_weights_99.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "std_scaler_aut = joblib.load('../modelli/std_scaler_aut.bin')\n",
    "std_scaler_dnn = joblib.load('../modelli/std_scaler_dnn.bin')\n",
    "columns = df.copy().drop('Label', axis=1).columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAdversarialResults(X_advs, df_advs, attack_type, num_total_attempts, dnn_target, aut_binary_th=0.05, context=''):\n",
    "    preds_advs_dnn = ModelUtils.binary_preds_supervised(dnn_target, X_advs)\n",
    "    advs_samples_dnn = GeneralUtils.get_advs_samples(np.array(preds_advs_dnn), df_advs)\n",
    "    print(f'Successful adversarial samples of type {attack_type} for DNN {context}: {advs_samples_dnn.shape[0]} / {num_total_attempts} - ASR: {(advs_samples_dnn.shape[0]/num_total_attempts) * 100}%')\n",
    "\n",
    "    preds_advs_aut = ModelUtils.binary_preds_unsupervised(autoencoder, X_advs, aut_binary_th)\n",
    "    advs_samples_aut = GeneralUtils.get_advs_samples(np.array(preds_advs_aut), df_advs)\n",
    "    print(f'Successful adversarial samples of type {attack_type} for AUT {context}: {advs_samples_aut.shape[0]} / {num_total_attempts} - ASR: {(advs_samples_aut.shape[0]/num_total_attempts) * 100}%')\n",
    "\n",
    "    preds_advs_dnn_by_aut = ModelUtils.binary_preds_unsupervised(autoencoder, advs_samples_dnn.copy().drop('Label', axis=1), aut_binary_th)\n",
    "    common_advs_samples = GeneralUtils.get_advs_samples(np.array(preds_advs_dnn_by_aut), advs_samples_dnn)\n",
    "    print(f'Successful adversarial samples of type {attack_type} for TARGET SYSTEM {context}: {common_advs_samples.shape[0]} / {num_total_attempts} - ATSR: {(common_advs_samples.shape[0]/num_total_attempts) * 100}%')\n",
    "\n",
    "    #X_advs_with_preds = X_advs.assign(preds_dnn=preds_advs_dnn.astype(bool), preds_aut=np.array(preds_advs_aut).astype(bool))\n",
    "    #X_advs_target_system = X_advs_with_preds[(X_advs_with_preds['preds_dnn'] == False) | (X_advs_with_preds['preds_aut'] == False)]   \n",
    "    #print(f'Successful adversarial samples of type {attack_type} for TARGET SYSTEM {context}: {X_advs_target_system.shape[0]} / {X_advs.shape[0]} - Rate {(X_advs_target_system.shape[0] / X_advs.shape[0]) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Perform Black Box attacks***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_ADVS_CSV_PATH = '../csv/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HopSkipJump**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#dnn = load_model('../modelli/DNN_best_weights_99.hdf5')\n",
    "X_anomalous_to_perturb = std_scaler_dnn.transform(df_anomalous.sample(n=50000).drop('Label', axis=1))\n",
    "#dnn_target = KerasClassifier(model=dnn, clip_values=(X_anomalous_to_perturb.min(), X_anomalous_to_perturb.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hsj_attack = HopSkipJump(classifier=dnn_target)\n",
    "#hsj_advs = hsj_attack.generate(X_anomalous_to_perturb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful adversarial samples of type HOPSKIPJUMP for DNN : 49667 / 50000 - ASR: 99.334%\n",
      "Successful adversarial samples of type HOPSKIPJUMP for AUT : 21511 / 50000 - ASR: 43.022%\n",
      "Successful adversarial samples of type HOPSKIPJUMP for TARGET SYSTEM : 21500 / 50000 - ATSR: 43.0%\n"
     ]
    }
   ],
   "source": [
    "df_hsj, X_hsj, y_hsj = GeneralUtils.get_data_with_advs(BASE_ADVS_CSV_PATH + 'hsj_new.csv')\n",
    "checkAdversarialResults(X_hsj, df_hsj, 'HOPSKIPJUMP', X_anomalous_to_perturb.shape[0], dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boundary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#dnn = load_model('../modelli/DNN_best_weights_99.hdf5')\n",
    "X_anomalous_to_perturb = std_scaler_dnn.transform(df_anomalous.sample(n=50000).drop('Label', axis=1))\n",
    "#dnn_target = KerasClassifier(model=dnn, clip_values=(X_anomalous_to_perturb.min(), X_anomalous_to_perturb.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boundary_attack = BoundaryAttack(estimator=dnn_target, targeted=False, max_iter=0, delta=0.001, epsilon=0.001, verbose=False)\n",
    "#boundary_advs = boundary_attack.generate(X_anomalous_to_perturb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful adversarial samples of type BOUNDARY for DNN : 49847 / 50000 - ASR: 99.694%\n",
      "Successful adversarial samples of type BOUNDARY for AUT : 191 / 50000 - ASR: 0.382%\n",
      "Successful adversarial samples of type BOUNDARY for TARGET SYSTEM : 191 / 50000 - ATSR: 0.382%\n"
     ]
    }
   ],
   "source": [
    "df_boundary, X_boundary, y_boundary = GeneralUtils.get_data_with_advs(BASE_ADVS_CSV_PATH + 'boundary_new.csv')\n",
    "checkAdversarialResults(X_boundary, df_boundary, 'BOUNDARY', X_anomalous_to_perturb.shape[0], dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ZOO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#dnn = load_model('../modelli/DNN_best_weights_99.hdf5')\n",
    "X_anomalous_to_perturb = std_scaler_dnn.transform(df_anomalous.sample(n=50000).drop('Label', axis=1))\n",
    "#dnn_target = KerasClassifier(model=dnn, clip_values=(X_anomalous_to_perturb.min(), X_anomalous_to_perturb.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zoo_attack = ZooAttack(dnn_target, confidence=0.5, targeted=False, learning_rate=0.2, nb_parallel=48, use_resize=False, use_importance=False)\n",
    "#zoo_advs = zoo_attack.generate(X_anomalous_to_perturb)\n",
    "#pd.DataFrame(zoo_advs, columns=columns).to_csv(BASE_ADVS_CSV_PATH + 'zoo_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful adversarial samples of type ZOO for DNN : 3535 / 50000 - ASR: 7.07%\n",
      "Successful adversarial samples of type ZOO for AUT : 40192 / 50000 - ASR: 80.384%\n",
      "Successful adversarial samples of type ZOO for TARGET SYSTEM : 978 / 50000 - ATSR: 1.9560000000000002%\n"
     ]
    }
   ],
   "source": [
    "df_zoo, X_zoo, y_zoo = GeneralUtils.get_data_with_advs(BASE_ADVS_CSV_PATH + 'zoo_new.csv')\n",
    "checkAdversarialResults(X_zoo, df_zoo, 'ZOO', X_anomalous_to_perturb.shape[0], dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Query Efficient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#dnn = load_model('../modelli/DNN_best_weights_99.hdf5')\n",
    "X_anomalous_to_perturb = std_scaler_dnn.transform(df_anomalous.sample(n=50000).drop('Label', axis=1))\n",
    "#dnn_target = KerasClassifier(model=dnn, clip_values=(X_anomalous_to_perturb.min(), X_anomalous_to_perturb.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dnn_target_query_efficient_bb = QueryEfficientGradientEstimationClassifier(dnn_target, 20, 1 / 64.0, 0)\n",
    "#fgsmBB_attack_dnn = FastGradientMethod(dnn_target_query_efficient_bb, eps=1)\n",
    "#fgsmBB_advs_dnn = fgsmBB_attack_dnn.generate(X_anomalous_to_perturb, verbose=True)\n",
    "#pd.DataFrame(fgsmBB_advs_dnn, columns=columns).to_csv(BASE_ADVS_CSV_PATH + 'query_eff_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful adversarial samples of type QUERY EFF for DNN : 24205 / 50000 - ASR: 48.41%\n",
      "Successful adversarial samples of type QUERY EFF for AUT : 21389 / 50000 - ASR: 42.778%\n",
      "Successful adversarial samples of type QUERY EFF for TARGET SYSTEM : 37 / 50000 - ATSR: 0.074%\n"
     ]
    }
   ],
   "source": [
    "df_query_eff_new, X_query_eff_new, y_query_eff_new = GeneralUtils.get_data_with_advs(BASE_ADVS_CSV_PATH + 'query_eff_new.csv')\n",
    "checkAdversarialResults(X_query_eff_new, df_query_eff_new, 'QUERY EFF', X_anomalous_to_perturb.shape[0], dnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
