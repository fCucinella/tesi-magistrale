{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/lib/python3.11/site-packages/art/estimators/certification/__init__.py:29: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from art.attacks.evasion import DeepFool, CarliniL2Method\n",
    "from art.attacks.evasion.fast_gradient import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier\n",
    "\n",
    "from adversarialdefence.utils import ModelUtils, GeneralUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Data Loading***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1715326, 49)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../csv/CICIDS2017_improved-preprocessed.csv')\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of benign samples: 1432918\n",
      "Number of anomalous samples: 282408\n"
     ]
    }
   ],
   "source": [
    "df_benign = df[df['Label'] == 0]\n",
    "df_anomalous = df[df['Label'] == 1]\n",
    "\n",
    "print(f'Number of benign samples: {df_benign.shape[0]}')\n",
    "print(f'Number of anomalous samples: {df_anomalous.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Load models and scalers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Nadam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "autoencoder = load_model('../modelli/autoencoder_best_weights_96-96.hdf5')\n",
    "dnn = load_model('../modelli/DNN_best_weights_99.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "std_scaler_aut = joblib.load('../modelli/std_scaler_aut.bin')\n",
    "std_scaler_dnn = joblib.load('../modelli/std_scaler_dnn.bin') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAdversarialResults(X_advs, df_advs, attack_type, num_total_attempts, dnn_target, aut_binary_th=0.05, context=''):\n",
    "    preds_advs_dnn = ModelUtils.binary_preds_supervised(dnn_target, X_advs)\n",
    "    advs_samples_dnn = GeneralUtils.get_advs_samples(np.array(preds_advs_dnn), df_advs)\n",
    "    print(f'Successful adversarial samples of type {attack_type} for DNN {context}: {advs_samples_dnn.shape[0]} / {num_total_attempts} - ASR: {(advs_samples_dnn.shape[0]/num_total_attempts) * 100}%')\n",
    "\n",
    "    preds_advs_aut = ModelUtils.binary_preds_unsupervised(autoencoder, X_advs, aut_binary_th)\n",
    "    advs_samples_aut = GeneralUtils.get_advs_samples(np.array(preds_advs_aut), df_advs)\n",
    "    print(f'Successful adversarial samples of type {attack_type} for AUT {context}: {advs_samples_aut.shape[0]} / {num_total_attempts} - ASR: {(advs_samples_aut.shape[0]/num_total_attempts) * 100}%')\n",
    "\n",
    "    preds_advs_dnn_by_aut = ModelUtils.binary_preds_unsupervised(autoencoder, advs_samples_dnn.copy().drop('Label', axis=1), aut_binary_th)\n",
    "    common_advs_samples = GeneralUtils.get_advs_samples(np.array(preds_advs_dnn_by_aut), advs_samples_dnn)\n",
    "    print(f'Successful adversarial samples of type {attack_type} for TARGET SYSTEM {context}: {common_advs_samples.shape[0]} / {num_total_attempts} - ATSR: {(common_advs_samples.shape[0]/num_total_attempts) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Perform WB Attacks***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_ADVS_CSV_PATH = '../csv/'\n",
    "X_anomalous_to_perturb = std_scaler_dnn.transform(df_anomalous.drop('Label', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#dnn = load_model('../modelli/DNN_best_weights_99.hdf5')\n",
    "#dnn_target = KerasClassifier(model=dnn, clip_values=(X_anomalous_to_perturb.min(), X_anomalous_to_perturb.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FGSM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fgsm_attack = FastGradientMethod(dnn_target, eps=0.07)\n",
    "#fgsm_advs = fgsm_attack.generate(X_anomalous_to_perturb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful adversarial samples of type FGSM for DNN : 94759 / 282408 - ASR: 33.55393614911759%\n",
      "Successful adversarial samples of type FGSM for AUT : 16858 / 282408 - ASR: 5.969377638027251%\n",
      "Successful adversarial samples of type FGSM for TARGET SYSTEM : 4645 / 282408 - ATSR: 1.6447834338970568%\n"
     ]
    }
   ],
   "source": [
    "df_fgsm, X_fgsm, y_fgsm = GeneralUtils.get_data_with_advs(BASE_ADVS_CSV_PATH + 'fgsm.csv')\n",
    "checkAdversarialResults(X_fgsm, df_fgsm, 'FGSM', X_anomalous_to_perturb.shape[0], dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deepfool Attack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deepFool_attack = DeepFool(dnn_target, max_iter=1)\n",
    "#deepFool_advs = deepFool_attack.generate(X_anomalous_to_perturb, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful adversarial samples of type DEEPFOOL for DNN : 238261 / 282408 - ASR: 84.36765247443415%\n",
      "Successful adversarial samples of type DEEPFOOL for AUT : 24430 / 282408 - ASR: 8.650604798730914%\n",
      "Successful adversarial samples of type DEEPFOOL for TARGET SYSTEM : 206 / 282408 - ATSR: 0.0729441092320331%\n"
     ]
    }
   ],
   "source": [
    "df_deepFool, X_deepFool, y_deepFool = GeneralUtils.get_data_with_advs(BASE_ADVS_CSV_PATH + 'deepFool.csv')\n",
    "checkAdversarialResults(X_deepFool, df_deepFool, 'DEEPFOOL', X_anomalous_to_perturb.shape[0], dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carlini Attack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carlini_attack = CarliniL2Method(dnn_target, max_iter=2, batch_size=1, targeted=False)\n",
    "#step = 5043\n",
    "\n",
    "#for i in range(53, 57):\n",
    "#    start = step * (i - 1)\n",
    "#    end = step * i\n",
    "#    X_anomalous_to_perturb_process = X_anomalous_to_perturb[start:end]\n",
    "#    carlini_advs = carlini_attack.generate(X_anomalous_to_perturb_process)\n",
    "#    df_carlini = pd.DataFrame(carlini_advs, columns=columns).to_csv('carlini_' + str(i) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful adversarial samples of type CARLINI  for DNN : 25331 / 282408 - ASR: 8.96964675221665%\n",
      "Successful adversarial samples of type CARLINI  for AUT : 229525 / 282408 - ASR: 81.27425568680773%\n",
      "Successful adversarial samples of type CARLINI  for TARGET SYSTEM : 11243 / 282408 - ATSR: 3.9811195150279026%\n"
     ]
    }
   ],
   "source": [
    "df_carlini, X_carlini, y_carlini= GeneralUtils.get_data_with_advs(BASE_ADVS_CSV_PATH + 'carlini.csv')\n",
    "X_carlini.drop(X_carlini.columns[0], axis=1, inplace=True)\n",
    "df_carlini.drop(df_carlini.columns[0], axis=1, inplace=True)\n",
    "\n",
    "checkAdversarialResults(X_carlini, df_carlini, 'CARLINI ', X_anomalous_to_perturb.shape[0], dnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
