{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from keras.models import load_model\n",
    "\n",
    "from adversarialdefence.mutation_testing import AdversarialDetectorThroughMutation\n",
    "from adversarialdefence.model_mut_operators import ModelMutationOperators\n",
    "\n",
    "from adversarialdefence.utils import ModelUtils, GeneralUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Data Loading***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1715326, 49)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../csv/CICIDS2017_improved-preprocessed.csv')\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of benign samples: 1432918\n",
      "Number of anomalous samples: 282408\n"
     ]
    }
   ],
   "source": [
    "df_benign = df[df['Label'] == 0]\n",
    "df_anomalous = df[df['Label'] == 1]\n",
    "\n",
    "print(f'Number of benign samples: {df_benign.shape[0]}')\n",
    "print(f'Number of anomalous samples: {df_anomalous.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Load Models and Scalers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Nadam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "autoencoder = load_model('../modelli/autoencoder_best_weights_96-96.hdf5')\n",
    "dnn = load_model('../modelli/DNN_best_weights_99.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "std_scaler_aut = joblib.load('../modelli/std_scaler_aut.bin')\n",
    "std_scaler_dnn = joblib.load('../modelli/std_scaler_dnn.bin')\n",
    "columns = df.copy().drop('Label', axis=1).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Load WB adversarial samples***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_advs_csv_path = '../csv/'\n",
    "\n",
    "df_fgsm, X_fgsm, y_fgsm = GeneralUtils.get_data_with_advs(base_advs_csv_path + 'fgsm.csv')\n",
    "df_deepFool, X_deepFool, y_deepFool = GeneralUtils.get_data_with_advs(base_advs_csv_path + 'deepFool.csv')\n",
    "df_carlini, X_carlini, y_carlini = GeneralUtils.get_data_with_advs(base_advs_csv_path + 'carlini.csv')\n",
    "\n",
    "X_carlini.drop(X_carlini.columns[0], axis=1, inplace=True)\n",
    "df_carlini.drop(df_carlini.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_fgsm_dnn = ModelUtils.binary_preds_supervised(dnn, X_fgsm)\n",
    "preds_deepFool_dnn = ModelUtils.binary_preds_supervised(dnn, X_deepFool)\n",
    "preds_carlini_dnn = ModelUtils.binary_preds_supervised(dnn, X_carlini)\n",
    "\n",
    "preds_fgsm_aut = ModelUtils.binary_preds_unsupervised(autoencoder, X_fgsm)\n",
    "preds_deepFool_aut = ModelUtils.binary_preds_unsupervised(autoencoder, X_deepFool)\n",
    "preds_carlini_aut = ModelUtils.binary_preds_unsupervised(autoencoder, X_carlini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "advs_fgsm_dnn = GeneralUtils.get_advs_samples(preds_fgsm_dnn, df_fgsm)\n",
    "advs_deepFool_dnn = GeneralUtils.get_advs_samples(preds_deepFool_dnn, df_deepFool)\n",
    "advs_carlini_dnn = GeneralUtils.get_advs_samples(preds_carlini_dnn, df_carlini)\n",
    "\n",
    "advs_fgsm_aut = GeneralUtils.get_advs_samples(preds_fgsm_aut, df_fgsm)\n",
    "advs_deepFool_aut = GeneralUtils.get_advs_samples(preds_deepFool_aut, df_deepFool)\n",
    "advs_carlini_aut = GeneralUtils.get_advs_samples(preds_carlini_aut, df_carlini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of adversarial samples for dnn: 358351\n",
      "Number of adversarial samples for aut: 270813\n"
     ]
    }
   ],
   "source": [
    "df_advs_dnn = pd.concat([advs_fgsm_dnn, advs_deepFool_dnn, advs_carlini_dnn], ignore_index=True).sample(frac=1)\n",
    "df_advs_aut = pd.concat([advs_fgsm_aut, advs_deepFool_aut, advs_carlini_aut], ignore_index=True).sample(frac=1)\n",
    "\n",
    "print(f'Number of adversarial samples for dnn: {df_advs_dnn.shape[0]}')\n",
    "print(f'Number of adversarial samples for aut: {df_advs_aut.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Check Mutation Testing results***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_benign = df_benign.sample(n=1000)\n",
    "y_benign = X_benign.pop('Label')\n",
    "\n",
    "X_benign_dnn = std_scaler_dnn.transform(X_benign)\n",
    "X_benign_aut = std_scaler_aut.transform(X_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WB_ADVS_SAMPLES = 1000\n",
    "wb_attacks_dnn_dict = {\n",
    "    'FGSM': advs_fgsm_dnn.sample(n=N_WB_ADVS_SAMPLES).drop('Label', axis=1), \n",
    "    'DEEPFOOL': advs_deepFool_dnn.sample(n=N_WB_ADVS_SAMPLES).drop('Label', axis=1), \n",
    "    'CARLINI': advs_carlini_dnn.sample(n=N_WB_ADVS_SAMPLES).drop('Label', axis=1), \n",
    "    'BENIGN': X_benign_dnn\n",
    "}\n",
    "\n",
    "wb_attacks_aut_dict = {\n",
    "    'FGSM': advs_fgsm_aut.sample(n=N_WB_ADVS_SAMPLES).drop('Label', axis=1), \n",
    "    'DEEPFOOL': advs_deepFool_aut.sample(n=N_WB_ADVS_SAMPLES).drop('Label', axis=1), \n",
    "    'CARLINI': advs_carlini_aut.sample(n=N_WB_ADVS_SAMPLES).drop('Label', axis=1), \n",
    "    'BENIGN': X_benign_aut\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutated_models(orig_model, num_mutation, mutation_ratio, mutation_operator):\n",
    "        mutated_models = []\n",
    "        for i in range(0, num_mutation):\n",
    "            if mutation_operator == 'NAI':\n",
    "                mutated_model = ModelMutationOperators.NAI_mut(orig_model, mutation_ratio)\n",
    "            elif mutation_operator == 'GF':\n",
    "                mutated_model = ModelMutationOperators.GF_mut(orig_model, mutation_ratio)\n",
    "            elif mutation_operator == 'WS':\n",
    "                mutated_model = ModelMutationOperators.WS_mut(orig_model, mutation_ratio)\n",
    "            else:\n",
    "                raise Exception('Mutation operator not valid. Choose between [NAI, GF, WS]')\n",
    "            mutated_models.append(mutated_model)\n",
    "\n",
    "        return mutated_models\n",
    "\n",
    "def get_LCR_metrics(X, mutated_models, orig_model, model_type):\n",
    "    LCR_list = [None] * X.shape[0]\n",
    "    num_deflected_models = np.zeros(X.shape[0])\n",
    "\n",
    "    for mutated_model in mutated_models:\n",
    "        if model_type == 'SUPERVISED':\n",
    "            orig_labels = ModelUtils.binary_preds_supervised(orig_model, X)\n",
    "            mutated_labels = ModelUtils.binary_preds_supervised(mutated_model, X)\n",
    "        else:\n",
    "            orig_labels = ModelUtils.binary_preds_unsupervised(orig_model, X)\n",
    "            mutated_labels = ModelUtils.binary_preds_unsupervised(mutated_model, X)\n",
    "\n",
    "        for i in range(0, len(orig_labels)):\n",
    "            if orig_labels[i] != mutated_labels[i]:\n",
    "                num_deflected_models[i] = num_deflected_models[i] + 1\n",
    "    \n",
    "        for i in range(0, len(LCR_list)):\n",
    "            LCR_list[i] = num_deflected_models[i] / len(mutated_models)\n",
    "    \n",
    "    return sum(LCR_list) / len(LCR_list), max(LCR_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutation testing on DNN\n",
      "\n",
      "Mutation operator: GF; mutation rate: 0.25\n",
      "  - LCR_avg on FGSM adversarial samples: 0.12895000000000015\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.0007849999999999999\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.09023500000000001\n",
      "  - LCR_avg on non adversarial samples: 0.0014399999999999997\n",
      "Mutation operator: GF; mutation rate: 0.3\n",
      "  - LCR_avg on FGSM adversarial samples: 0.1292100000000001\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.0008100000000000001\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.08964000000000001\n",
      "  - LCR_avg on non adversarial samples: 0.0016299999999999995\n",
      "Mutation operator: GF; mutation rate: 0.4\n",
      "  - LCR_avg on FGSM adversarial samples: 0.14793999999999985\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.000885\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.10297999999999985\n",
      "  - LCR_avg on non adversarial samples: 0.0018849999999999995\n",
      "Mutation operator: NAI; mutation rate: 0.25\n",
      "  - LCR_avg on FGSM adversarial samples: 0.18432499999999968\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.013169999999999994\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.23877499999999985\n",
      "  - LCR_avg on non adversarial samples: 0.016055000000000038\n",
      "Mutation operator: NAI; mutation rate: 0.3\n",
      "  - LCR_avg on FGSM adversarial samples: 0.18005999999999983\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.035575\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.24852499999999944\n",
      "  - LCR_avg on non adversarial samples: 0.02181500000000009\n",
      "Mutation operator: NAI; mutation rate: 0.4\n",
      "  - LCR_avg on FGSM adversarial samples: 0.24345999999999982\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.25529\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.3453950000000001\n",
      "  - LCR_avg on non adversarial samples: 0.10597500000000026\n",
      "Mutation operator: WS; mutation rate: 0.25\n",
      "  - LCR_avg on FGSM adversarial samples: 0.055849999999999914\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.0006800000000000003\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.04561999999999991\n",
      "  - LCR_avg on non adversarial samples: 0.001205\n",
      "Mutation operator: WS; mutation rate: 0.3\n",
      "  - LCR_avg on FGSM adversarial samples: 0.05389000000000008\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.0006050000000000002\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.04555499999999999\n",
      "  - LCR_avg on non adversarial samples: 0.0013949999999999987\n",
      "Mutation operator: WS; mutation rate: 0.4\n",
      "  - LCR_avg on FGSM adversarial samples: 0.03523500000000005\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.00029000000000000006\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.029079999999999995\n",
      "  - LCR_avg on non adversarial samples: 0.0009350000000000005\n"
     ]
    }
   ],
   "source": [
    "mut_rates_dnn = [0.25, 0.3, 0.4]\n",
    "mut_operators = ['GF', 'NAI', 'WS']\n",
    "\n",
    "print('Mutation testing on DNN\\n')\n",
    "for mut_operator in mut_operators:\n",
    "    for mut_rate in mut_rates_dnn:\n",
    "        mutated_models = get_mutated_models(dnn, 200, mut_rate, mut_operator)\n",
    "        print(f'Mutation operator: {mut_operator}; mutation rate: {mut_rate}')\n",
    "        for attack in wb_attacks_dnn_dict:\n",
    "            LCR_avg = get_LCR_metrics(wb_attacks_dnn_dict[attack], mutated_models, dnn, 'SUPERVISED')\n",
    "            print(f'  - LCR_avg on {attack} adversarial samples: {LCR_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutation testing on AUTOENCODER\n",
      "Mutation operator: GF; mutation rate: 0.025\n",
      "  - LCR_avg on FGSM adversarial samples: 0.9980750000000012\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.987200000000004\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.9728700000000013\n",
      "  - LCR_avg on non adversarial samples: 0.4132800000000009\n",
      "Mutation operator: GF; mutation rate: 0.03\n",
      "  - LCR_avg on FGSM adversarial samples: 0.9992400000000005\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.9954000000000031\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.9851950000000013\n",
      "  - LCR_avg on non adversarial samples: 0.44126500000000074\n",
      "Mutation operator: GF; mutation rate: 0.04\n",
      "  - LCR_avg on FGSM adversarial samples: 0.999895\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.9999250000000001\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.9975950000000007\n",
      "  - LCR_avg on non adversarial samples: 0.5256499999999995\n",
      "Mutation operator: NAI; mutation rate: 0.025\n",
      "  - LCR_avg on FGSM adversarial samples: 0.9967650000000026\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.9876350000000078\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.9839900000000055\n",
      "  - LCR_avg on non adversarial samples: 0.8650550000000035\n",
      "Mutation operator: NAI; mutation rate: 0.03\n",
      "  - LCR_avg on FGSM adversarial samples: 0.99999\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.99999\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.9996700000000002\n",
      "  - LCR_avg on non adversarial samples: 0.9349750000000076\n",
      "Mutation operator: NAI; mutation rate: 0.04\n",
      "  - LCR_avg on FGSM adversarial samples: 0.999995\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 1.0\n",
      "  - LCR_avg on CARLINI adversarial samples: 1.0\n",
      "  - LCR_avg on non adversarial samples: 0.9259850000000056\n",
      "Mutation operator: WS; mutation rate: 0.025\n",
      "  - LCR_avg on FGSM adversarial samples: 0.990155000000006\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.9650800000000045\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.9510400000000068\n",
      "  - LCR_avg on non adversarial samples: 0.687085000000002\n",
      "Mutation operator: WS; mutation rate: 0.03\n",
      "  - LCR_avg on FGSM adversarial samples: 0.9988900000000009\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.9983900000000013\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.9941500000000032\n",
      "  - LCR_avg on non adversarial samples: 0.8267700000000017\n",
      "Mutation operator: WS; mutation rate: 0.04\n",
      "  - LCR_avg on FGSM adversarial samples: 0.9975850000000018\n",
      "  - LCR_avg on DEEPFOOL adversarial samples: 0.9934500000000048\n",
      "  - LCR_avg on CARLINI adversarial samples: 0.990280000000005\n",
      "  - LCR_avg on non adversarial samples: 0.8410900000000017\n"
     ]
    }
   ],
   "source": [
    "mut_rates_aut = [0.025, 0.03, 0.04]\n",
    "print('Mutation testing on AUTOENCODER')\n",
    "for mut_operator in mut_operators:\n",
    "    for mut_rate in mut_rates_aut:\n",
    "        mutated_models = get_mutated_models(autoencoder, 200, mut_rate, mut_operator)\n",
    "        print(f'Mutation operator: {mut_operator}; mutation rate: {mut_rate}')\n",
    "        for attack in wb_attacks_aut_dict:\n",
    "            LCR_avg = get_LCR_metrics(wb_attacks_aut_dict[attack], mutated_models, autoencoder, 'UNSUPERVISED')\n",
    "            print(f'  - LCR_avg on {attack} adversarial samples: {LCR_avg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Detection on WB adversarial samples***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUTATED_MODELS_BASE_PATH = '../modelli/mutation/'\n",
    "adv_detector_dnn = AdversarialDetectorThroughMutation(dnn, 'DNN', 'SUPERVISED', 0.5, MUTATED_MODELS_BASE_PATH)\n",
    "adv_detector_aut = AdversarialDetectorThroughMutation(autoencoder, 'AUT', 'UNSUPERVISED', 0.05, MUTATED_MODELS_BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "LCR_th_dnn = adv_detector_dnn.fit(X_benign_dnn, 500, 0.3)\n",
    "LCR_th_aut = adv_detector_aut.fit(X_benign_aut, 500, 0.006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_detection(X, detector, max_iter, detection_sensibility, attack, n_step):\n",
    "    num_detected_list = []\n",
    "    for i in range(0, n_step):\n",
    "        detect_status = detector.detect(X, max_iter, detection_sensibility)\n",
    "        num_detected_list.append(len([d for d in detect_status if d == True]))\n",
    "    \n",
    "    avg_detected = sum(num_detected_list) / len(num_detected_list)\n",
    "    print(f'Average number of samples detected as adversarial on 5 attempts for {attack}: {avg_detected} / {X.shape[0]} - Ratio: {(avg_detected/X.shape[0]) * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of samples detected as adversarial on 5 attempts for FGSM: 909.6 / 1000 - Ratio: 90.96000000000001\n",
      "Average number of samples detected as adversarial on 5 attempts for DEEPFOOL: 267.6 / 1000 - Ratio: 26.76\n",
      "Average number of samples detected as adversarial on 5 attempts for CARLINI: 913.0 / 1000 - Ratio: 91.3\n",
      "Average number of samples detected as adversarial on 5 attempts for BENIGN: 123.6 / 1000 - Ratio: 12.36\n"
     ]
    }
   ],
   "source": [
    "for attack in wb_attacks_dnn_dict:\n",
    "    X_advs = wb_attacks_dnn_dict[attack]\n",
    "    perform_detection(X_advs, adv_detector_dnn, 200, 0.2, attack, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of samples detected as adversarial on 5 attempts for FGSM: 874.0 / 1000 - Ratio: 87.4\n",
      "Average number of samples detected as adversarial on 5 attempts for DEEPFOOL: 631.2 / 1000 - Ratio: 63.12000000000001\n",
      "Average number of samples detected as adversarial on 5 attempts for CARLINI: 716.4 / 1000 - Ratio: 71.63999999999999\n",
      "Average number of samples detected as adversarial on 5 attempts for BENIGN: 204.6 / 1000 - Ratio: 20.46\n"
     ]
    }
   ],
   "source": [
    "for attack in wb_attacks_aut_dict:\n",
    "    X_advs = wb_attacks_aut_dict[attack]\n",
    "    perform_detection(X_advs, adv_detector_aut, 200, 0.7, attack, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Detection on BB Adversarial samples***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hsj, X_hsj, y_hsj = GeneralUtils.get_data_with_advs(base_advs_csv_path + 'hsj_new.csv')\n",
    "df_zoo, X_zoo, y_zoo = GeneralUtils.get_data_with_advs(base_advs_csv_path + 'zoo_new.csv')\n",
    "df_boundary, X_boundary, y_boundary = GeneralUtils.get_data_with_advs(base_advs_csv_path + 'boundary_new.csv')\n",
    "df_query_eff, X_query_eff, y_query_eff = GeneralUtils.get_data_with_advs(base_advs_csv_path + 'query_eff_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_hsj_dnn = ModelUtils.binary_preds_supervised(dnn, X_hsj)\n",
    "preds_zoo_dnn = ModelUtils.binary_preds_supervised(dnn, X_zoo)\n",
    "preds_boundary_dnn = ModelUtils.binary_preds_supervised(dnn, X_boundary)\n",
    "preds_query_eff_dnn = ModelUtils.binary_preds_supervised(dnn, X_query_eff)\n",
    "\n",
    "preds_hsj_aut = ModelUtils.binary_preds_unsupervised(autoencoder, X_hsj)\n",
    "preds_zoo_aut = ModelUtils.binary_preds_unsupervised(autoencoder, X_zoo)\n",
    "preds_boundary_aut = ModelUtils.binary_preds_unsupervised(autoencoder, X_boundary)\n",
    "preds_query_eff_aut = ModelUtils.binary_preds_unsupervised(autoencoder, X_query_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "advs_hsj_dnn = GeneralUtils.get_advs_samples(preds_hsj_dnn, df_hsj)\n",
    "advs_zoo_dnn = GeneralUtils.get_advs_samples(preds_zoo_dnn, df_zoo)\n",
    "advs_boundary_dnn = GeneralUtils.get_advs_samples(preds_boundary_dnn, df_boundary)\n",
    "advs_query_eff_dnn = GeneralUtils.get_advs_samples(preds_query_eff_dnn, df_query_eff)\n",
    "\n",
    "advs_hsj_aut = GeneralUtils.get_advs_samples(preds_hsj_aut, df_hsj)\n",
    "advs_zoo_aut = GeneralUtils.get_advs_samples(preds_zoo_aut, df_zoo)\n",
    "advs_boundary_aut = GeneralUtils.get_advs_samples(preds_boundary_aut, df_boundary)\n",
    "advs_query_eff_aut = GeneralUtils.get_advs_samples(preds_query_eff_aut, df_query_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of adversarial samples BB for dnn: 127254\n",
      "Number of adversarial samples BB for aut: 83283\n"
     ]
    }
   ],
   "source": [
    "df_advs_BB_dnn = pd.concat([advs_hsj_dnn, advs_zoo_dnn, advs_boundary_dnn, advs_query_eff_dnn], ignore_index=True).sample(frac=1)\n",
    "df_advs_BB_aut = pd.concat([advs_hsj_aut, advs_zoo_aut, advs_boundary_aut, advs_query_eff_aut], ignore_index=True).sample(frac=1)\n",
    "\n",
    "print(f'Number of adversarial samples BB for dnn: {df_advs_BB_dnn.shape[0]}')\n",
    "print(f'Number of adversarial samples BB for aut: {df_advs_BB_aut.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_advs_BB_aut = df_advs_BB_aut.copy()\n",
    "y_advs_BB_aut = X_advs_BB_aut.pop('Label')\n",
    "\n",
    "X_advs_BB_dnn = df_advs_BB_dnn.copy()\n",
    "y_advs_BB_dnn = X_advs_BB_dnn.pop('Label')\n",
    "\n",
    "X_benign = df_benign.sample(n=1000)\n",
    "y_benign = X_benign.pop('Label')\n",
    "\n",
    "X_benign_dnn = std_scaler_dnn.transform(X_benign)\n",
    "X_benign_aut = std_scaler_aut.transform(X_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_attacks_dnn_dict = {\n",
    "    'HOPSKIPJUMP': advs_hsj_dnn.sample(n=1000).drop('Label', axis=1), \n",
    "    'BOUNDARY': advs_boundary_dnn.sample(n=1000).drop('Label', axis=1), \n",
    "    'ZOO': advs_zoo_dnn.sample(n=1000).drop('Label', axis=1), \n",
    "    'QUERY_EFF': advs_query_eff_dnn.sample(n=1000).drop('Label', axis=1)\n",
    "}\n",
    "\n",
    "bb_attacks_aut_dict = {\n",
    "    'HOPSKIPJUMP': advs_hsj_aut.sample(n=1000).drop('Label', axis=1), \n",
    "    'BOUNDARY': advs_boundary_aut.drop('Label', axis=1), \n",
    "    'ZOO': advs_zoo_aut.sample(n=1000).drop('Label', axis=1), \n",
    "    'QUERY_EFF': advs_query_eff_aut.sample(n=1000).drop('Label', axis=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of samples detected as adversarial on 5 attempts for HOPSKIPJUMP: 993.0 / 1000 - Ratio: 99.3\n",
      "Average number of samples detected as adversarial on 5 attempts for BOUNDARY: 985.8 / 1000 - Ratio: 98.58\n",
      "Average number of samples detected as adversarial on 5 attempts for ZOO: 776.6 / 1000 - Ratio: 77.66000000000001\n",
      "Average number of samples detected as adversarial on 5 attempts for QUERY_EFF: 112.8 / 1000 - Ratio: 11.28\n"
     ]
    }
   ],
   "source": [
    "for attack in bb_attacks_dnn_dict:\n",
    "    X_advs = bb_attacks_dnn_dict[attack]\n",
    "    perform_detection(X_advs, adv_detector_dnn, 200, 0.2, attack, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of samples detected as adversarial on 5 attempts for HOPSKIPJUMP: 851.2 / 1000 - Ratio: 85.12\n",
      "Average number of samples detected as adversarial on 5 attempts for BOUNDARY: 66.4 / 191 - Ratio: 34.76439790575917\n",
      "Average number of samples detected as adversarial on 5 attempts for ZOO: 681.4 / 1000 - Ratio: 68.14\n",
      "Average number of samples detected as adversarial on 5 attempts for QUERY_EFF: 680.2 / 1000 - Ratio: 68.02\n"
     ]
    }
   ],
   "source": [
    "for attack in bb_attacks_aut_dict:\n",
    "    X_advs = bb_attacks_aut_dict[attack]\n",
    "    perform_detection(X_advs, adv_detector_aut, 200, 0.7, attack, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Attempt 2***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCR_th_dnn = adv_detector_dnn.fit(X_benign_dnn, 500, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of samples detected as adversarial on 5 attempts for FGSM: 814.0 / 1000 - Ratio: 81.39999999999999\n",
      "Average number of samples detected as adversarial on 5 attempts for DEEPFOOL: 20.8 / 1000 - Ratio: 2.08\n",
      "Average number of samples detected as adversarial on 5 attempts for CARLINI: 702.8 / 1000 - Ratio: 70.28\n",
      "Average number of samples detected as adversarial on 5 attempts for BENIGN: 24.4 / 1000 - Ratio: 2.44\n"
     ]
    }
   ],
   "source": [
    "for attack in wb_attacks_dnn_dict:\n",
    "    X_advs = wb_attacks_dnn_dict[attack]\n",
    "    perform_detection(X_advs, adv_detector_dnn, 200, 0.02, attack, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of samples detected as adversarial on 5 attempts for HOPSKIPJUMP: 989.0 / 1000 - Ratio: 98.9\n",
      "Average number of samples detected as adversarial on 5 attempts for BOUNDARY: 380.8 / 1000 - Ratio: 38.080000000000005\n",
      "Average number of samples detected as adversarial on 5 attempts for ZOO: 522.8 / 1000 - Ratio: 52.279999999999994\n",
      "Average number of samples detected as adversarial on 5 attempts for QUERY_EFF: 6.0 / 1000 - Ratio: 0.6\n"
     ]
    }
   ],
   "source": [
    "for attack in bb_attacks_dnn_dict:\n",
    "    X_advs = bb_attacks_dnn_dict[attack]\n",
    "    perform_detection(X_advs, adv_detector_dnn, 200, 0.02, attack, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
